{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8daf041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "class CommonBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride):\n",
    "        super(CommonBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "\n",
    "        x += identity\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class SpecialBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride):\n",
    "        super(SpecialBlock, self).__init__()\n",
    "        self.change_channel = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride[0], padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channel)\n",
    "        )\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride[0], padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride[1], padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.change_channel(x)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "\n",
    "        x += identity\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, classes_num):\n",
    "        super(ResNet34, self).__init__()\n",
    "        self.prepare = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, 2, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            CommonBlock(64, 64, 1),\n",
    "            CommonBlock(64, 64, 1),\n",
    "            CommonBlock(64, 64, 1)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            SpecialBlock(64, 128, [2, 1]),\n",
    "            CommonBlock(128, 128, 1),\n",
    "            CommonBlock(128, 128, 1),\n",
    "            CommonBlock(128, 128, 1)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            SpecialBlock(128, 256, [2, 1]),\n",
    "            CommonBlock(256, 256, 1),\n",
    "            CommonBlock(256, 256, 1),\n",
    "            CommonBlock(256, 256, 1),\n",
    "            CommonBlock(256, 256, 1),\n",
    "            CommonBlock(256, 256, 1)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            SpecialBlock(256, 512, [2, 1]),\n",
    "            CommonBlock(512, 512, 1),\n",
    "            CommonBlock(512, 512, 1)\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, classes_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prepare(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c5a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "acc = []\n",
    "x_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef3eef14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet34(\n",
      "  (prepare): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): CommonBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): CommonBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): CommonBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): SpecialBlock(\n",
      "      (change_channel): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): CommonBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): CommonBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): CommonBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): SpecialBlock(\n",
      "      (change_channel): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): CommonBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): CommonBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): CommonBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): CommonBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): CommonBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): SpecialBlock(\n",
      "      (change_channel): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): CommonBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): CommonBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "0 loss: 0.24245496094226837\n",
      "0 test acc: 0.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DownLoad\\Anaconda\\anaconda\\envs\\myPytorch\\lib\\site-packages\\gradio\\inputs.py:259: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "D:\\DownLoad\\Anaconda\\anaconda\\envs\\myPytorch\\lib\\site-packages\\gradio\\inputs.py:262: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "D:\\DownLoad\\Anaconda\\anaconda\\envs\\myPytorch\\lib\\site-packages\\gradio\\outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "D:\\DownLoad\\Anaconda\\anaconda\\envs\\myPytorch\\lib\\site-packages\\gradio\\outputs.py:200: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  super().__init__(num_top_classes=num_top_classes, type=type, label=label)\n"
     ]
    },
    {
     "ename": "DuplicateBlockError",
     "evalue": "A block with id: 338 has already been rendered in the current Blocks.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateBlockError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 137>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    142\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mLabel(num_top_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m#bottom1 = gr.Button()\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m#bottom1.click(predict, inputs=inputs, outputs=outputs)\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     interface \u001b[38;5;241m=\u001b[39m \u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gr\u001b[38;5;241m.\u001b[39mTab(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m): \u001b[38;5;66;03m#标签页2\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     interface \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mInterface(fn\u001b[38;5;241m=\u001b[39mshow_loss, inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\DownLoad\\Anaconda\\anaconda\\envs\\myPytorch\\lib\\site-packages\\gradio\\interface.py:421\u001b[0m, in \u001b[0;36mInterface.__init__\u001b[1;34m(self, fn, inputs, outputs, examples, cache_examples, examples_per_page, live, interpretation, num_shap, title, description, article, thumbnail, theme, css, allow_flagging, flagging_options, flagging_dir, flagging_callback, analytics_enabled, batch, max_batch_size, _api_mode, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Row(equal_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface_type \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    409\u001b[0m         InterfaceTypes\u001b[38;5;241m.\u001b[39mSTANDARD,\n\u001b[0;32m    410\u001b[0m         InterfaceTypes\u001b[38;5;241m.\u001b[39mINPUT_ONLY,\n\u001b[0;32m    411\u001b[0m         InterfaceTypes\u001b[38;5;241m.\u001b[39mUNIFIED,\n\u001b[0;32m    412\u001b[0m     ]:\n\u001b[0;32m    413\u001b[0m         (\n\u001b[0;32m    414\u001b[0m             submit_btn,\n\u001b[0;32m    415\u001b[0m             clear_btn,\n\u001b[0;32m    416\u001b[0m             stop_btn,\n\u001b[0;32m    417\u001b[0m             flag_btns,\n\u001b[0;32m    418\u001b[0m             input_component_column,\n\u001b[0;32m    419\u001b[0m             interpret_component_column,\n\u001b[0;32m    420\u001b[0m             interpretation_set,\n\u001b[1;32m--> 421\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_input_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface_type \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    423\u001b[0m         InterfaceTypes\u001b[38;5;241m.\u001b[39mSTANDARD,\n\u001b[0;32m    424\u001b[0m         InterfaceTypes\u001b[38;5;241m.\u001b[39mOUTPUT_ONLY,\n\u001b[0;32m    425\u001b[0m     ]:\n\u001b[0;32m    426\u001b[0m         (\n\u001b[0;32m    427\u001b[0m             submit_btn_out,\n\u001b[0;32m    428\u001b[0m             clear_btn_2_out,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    431\u001b[0m             interpretation_btn,\n\u001b[0;32m    432\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_output_column(submit_btn)\n",
      "File \u001b[1;32mD:\\DownLoad\\Anaconda\\anaconda\\envs\\myPytorch\\lib\\site-packages\\gradio\\interface.py:486\u001b[0m, in \u001b[0;36mInterface.render_input_column\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m input_component_column:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_components:\n\u001b[1;32m--> 486\u001b[0m         \u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpretation:\n\u001b[0;32m    488\u001b[0m     interpret_component_column \u001b[38;5;241m=\u001b[39m Column(visible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\DownLoad\\Anaconda\\anaconda\\envs\\myPytorch\\lib\\site-packages\\gradio\\blocks.py:112\u001b[0m, in \u001b[0;36mBlock.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03mAdds self into appropriate BlockContext\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Context\u001b[38;5;241m.\u001b[39mroot_block \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;129;01min\u001b[39;00m Context\u001b[38;5;241m.\u001b[39mroot_block\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DuplicateBlockError(\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA block with id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has already been rendered in the current Blocks.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    114\u001b[0m     )\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Context\u001b[38;5;241m.\u001b[39mblock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     Context\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mDuplicateBlockError\u001b[0m: A block with id: 338 has already been rendered in the current Blocks."
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "#  用CIFAR-10 数据集进行实验\n",
    "\n",
    "def main():\n",
    "    batchsz = 128\n",
    "\n",
    "    cifar_train = datasets.CIFAR10('D:/研究生/暑期培训/NO1/data', True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),  # 转化为tensor类型\n",
    "    # 从[0,1]归一化到[-1,1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平镜像\n",
    "    transforms.RandomErasing(scale=(0.04, 0.2), ratio=(0.5, 2)),  # 随机遮挡\n",
    "    transforms.RandomCrop(32, padding=4),  # 随机裁剪\n",
    "    ]), download=False)\n",
    "    cifar_train = DataLoader(cifar_train, batch_size=batchsz, shuffle=True)\n",
    "\n",
    "    cifar_test = datasets.CIFAR10('D:/研究生/暑期培训/NO1/data', False, transform=transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ]), download=False)\n",
    "    cifar_test = DataLoader(cifar_test, batch_size=batchsz, shuffle=True)\n",
    "\n",
    "    x, label = iter(cifar_train).next()\n",
    "    #print('x:', x.shape, 'label:', label.shape)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    #print(device)\n",
    "    # model = Lenet5().to(device)\n",
    "    model = ResNet34(10).to(device)\n",
    "    state_dict=torch.load('net_params.pth')\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    criteon = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "    print(model)\n",
    "    \n",
    "\n",
    "    for epoch in range(1):\n",
    "        \n",
    "        model.train()\n",
    "        for batchidx, (x, label) in enumerate(cifar_train):\n",
    "            # [b, 3, 32, 32]\n",
    "            # [b]\n",
    "            x, label = x.to(device), label.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            # logits: [b, 10]\n",
    "            # label:  [b]\n",
    "            # loss: tensor scalar\n",
    "            loss_epoch = criteon(logits, label)\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss_epoch.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        loss.append(loss_epoch.item())\n",
    "\n",
    "        print(epoch, 'loss:', loss_epoch.item())\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # test\n",
    "            total_correct = 0\n",
    "            total_num = 0\n",
    "            for x, label in cifar_test:\n",
    "                # [b, 3, 32, 32]\n",
    "                # [b]\n",
    "                x, label = x.to(device), label.to(device)\n",
    "\n",
    "                # [b, 10]\n",
    "                logits = model(x)\n",
    "                #print(logits)\n",
    "                # [b]\n",
    "                pred = logits.argmax(dim=1)\n",
    "                # [b] vs [b] => scalar tensor\n",
    "                correct = torch.eq(pred, label).float().sum().item()\n",
    "                total_correct += correct\n",
    "                total_num += x.size(0)\n",
    "                # print(correct)\n",
    "            acc_epoch = total_correct / total_num\n",
    "            acc.append(acc_epoch)\n",
    "            print(epoch, 'test acc:', acc_epoch)\n",
    "            \n",
    "        x_label.append(len(acc))\n",
    "    \n",
    "    #print('loss', loss, 'acc', acc)\n",
    "    #torch.save(model.state_dict(),'net_params.pth')\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model, x_label, loss, acc\n",
    "\n",
    "\n",
    "def predict(inp):\n",
    "    labels = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    inp = Image.fromarray(inp.astype('uint8'), 'RGB')\n",
    "    inp = transforms.ToTensor()(inp).unsqueeze(0)\n",
    "    device = torch.device(\"cuda\")\n",
    "    inp = inp.to(device)\n",
    "    state_dict=torch.load('net_params.pth')\n",
    "    model.load_state_dict(state_dict)\n",
    "    with torch.no_grad():\n",
    "        prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n",
    "    return {labels[i]: float(prediction[i]) for i in range(10)}\n",
    "\n",
    "def show_loss():\n",
    "    plt.plot(x_label, loss)\n",
    "    plt.savefig(fname=\"loss.png\")\n",
    "    lossImage_path = r\"./loss.png\"\n",
    "    #加载图片\n",
    "    lossImg=Image.open(lossImage_path)\n",
    "    \n",
    "    return lossImg \n",
    "\n",
    "def show_acc():\n",
    "    plt.plot(x_label, acc)\n",
    "    plt.savefig(fname=\"acc.png\")\n",
    "    accImage_path = r\"./acc.png\"\n",
    "    #加载图片\n",
    "    accImg=Image.open(accImage_path)\n",
    "    \n",
    "    return accImg\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model, x_label, loss, acc = main()\n",
    "    with gr.Blocks() as demo:\n",
    "        with gr.Tab(\"pic and label\"): #标签页1\n",
    "            inputs = gr.inputs.Image()\n",
    "            outputs = gr.outputs.Label(num_top_classes=3)\n",
    "            bottom1 = gr.Button()\n",
    "            bottom1.click(predict, inputs=inputs, outputs=outputs)\n",
    "        with gr.Tab(\"loss\"): #标签页2\n",
    "            interface = gr.Interface(fn=show_loss, inputs=None, outputs=\"image\")\n",
    "        with gr.Tab(\"acc\"):\n",
    "            interface = gr.Interface(fn=show_acc, inputs=None, outputs=\"image\")\n",
    "    \n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833abf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myPytorch] *",
   "language": "python",
   "name": "conda-env-myPytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
